{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torchvision\n","import os\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torchvision.transforms import ToTensor\n","from torch.utils.data.dataset import random_split\n","from torchvision import models\n","from torch.utils.data import Dataset\n","import torch.optim as optim"],"metadata":{"id":"FR3R1bdd_NfH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"iuLZfVC8_pBj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721819915818,"user_tz":-540,"elapsed":2665,"user":{"displayName":"khloe Lee","userId":"00481896776510683202"}},"outputId":"a35a8b5b-63e1-4e29-e6e9-0ce8c8064649"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd '/content/drive/MyDrive/AI_project'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgBYZrR2d2Y9","executionInfo":{"status":"ok","timestamp":1721819976071,"user_tz":-540,"elapsed":503,"user":{"displayName":"khloe Lee","userId":"00481896776510683202"}},"outputId":"c9a1b12e-f606-4ea6-e6f6-6ef8f0585d12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AI_project\n"]}]},{"cell_type":"code","source":["#Clone attack repository\n","# !git clone https://github.com/Harry24k/adversarial-attacks-pytorch.git\n","# !cd adversarial-attacks-pytorch/torchattacks\n","# !pip install -e .\n","# !mv adversarial-attacks-pytorch attacks"],"metadata":{"id":"3JmWe9tF5fkv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721819766261,"user_tz":-540,"elapsed":7790,"user":{"displayName":"khloe Lee","userId":"00481896776510683202"}},"outputId":"ba0403ef-4624-431b-f665-91a342f84a27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'adversarial-attacks-pytorch'...\n","remote: Enumerating objects: 3644, done.\u001b[K\n","remote: Counting objects: 100% (595/595), done.\u001b[K\n","remote: Compressing objects: 100% (183/183), done.\u001b[K\n","remote: Total 3644 (delta 434), reused 450 (delta 409), pack-reused 3049\u001b[K\n","Receiving objects: 100% (3644/3644), 51.81 MiB | 9.37 MiB/s, done.\n","Resolving deltas: 100% (2274/2274), done.\n","Obtaining file:///content\n","\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["from attacks.torchattacks import PGD\n","from Models import *"],"metadata":{"id":"MTZ7GNw9JRix"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Dataset Preparation"],"metadata":{"id":"M5aE2di45kT0"}},{"cell_type":"code","source":["train_transform = transforms.Compose([\n","        transforms.RandomCrop(32,padding=4),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","\n","test_transform =  transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform = train_transform)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","\n","                                       download=True, transform = test_transform)"],"metadata":{"id":"g-mL_jMg_JZd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Prepare Network"],"metadata":{"id":"ca2oALE09QHj"}},{"cell_type":"code","source":["class DenoiseLoss(nn.Module):\n","    def __init__(self, n, hard_mining = 0, norm = False):\n","        super(DenoiseLoss, self).__init__()\n","        self.n = n\n","        assert(hard_mining >= 0 and hard_mining <= 1)\n","        self.hard_mining = hard_mining\n","        self.norm = norm\n","\n","    def forward(self, x, y):\n","        loss = torch.pow(torch.abs(x - y), self.n) / self.n\n","        if self.hard_mining > 0:\n","            loss = loss.view(-1)\n","            k = int(loss.size(0) * self.hard_mining)\n","            loss, idcs = torch.topk(loss, k)\n","            y = y.view(-1)[idcs]\n","\n","        loss = loss.mean()\n","        if self.norm:\n","            norm = torch.pow(torch.abs(y), self.n)\n","            norm = norm.data.mean()\n","            loss = loss / norm\n","        return loss"],"metadata":{"id":"PECz4sWOS8HM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %cd 'content/drive'\n","class Net(nn.Module):\n","    def __init__(self, pre_res ,n = 2, hard_mining = 0, loss_norm = False):\n","        super(Net, self).__init__()\n","        self.denoiser = Denoise() #Denoiser: to be trained\n","        self.loss = DenoiseLoss(n, hard_mining, loss_norm)\n","        self.net = pre_res\n","        for param in self.net.parameters():\n","            param.requires_grad = False #Freeze the pretrained base model:Resnet in this case\n","\n","    def forward(self, orig_x, adv_x, requires_control = True, train = True):\n","        orig_outputs = self.net(orig_x)\n","\n","        if requires_control:\n","            control_outputs = self.net(adv_x)\n","            control_loss = self.loss(control_outputs, orig_outputs)\n","\n","        if train:\n","            adv_x.volatile = False\n","            for i in range(len(orig_outputs)):\n","                orig_outputs[i].volatile = False\n","        adv_x = self.denoiser(adv_x) #denoised adv_x\n","        adv_outputs = self.net(adv_x) #logit result\n","        loss = self.loss(adv_outputs, orig_outputs) #\n","        return orig_outputs, adv_outputs, loss"],"metadata":{"id":"s6eTl_jp442k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","def train(dataloader,net, attack,optimizer): #adv+benign 1:1\n","    criterion =  nn.CrossEntropyLoss()\n","    net.train()\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    train_loss, train_acc = 0, 0\n","    for batch, (X, y) in enumerate(dataloader):\n","        if(batch%20==0):\n","          print(f'batch no. {batch}')\n","        X = X.to(device)\n","        y = y.to(device)\n","        optimizer.zero_grad()\n","        adv_x = attack(X,y)\n","        orig_outputs,adv_outputs,loss = net(X, adv_x, requires_control = True, train = True)\n","        loss = loss+criterion(adv_outputs,y) #clean 과 denoised의 logit간 차이+denoised CE loss\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        train_acc += (orig_outputs.argmax(1) == y).type(torch.float).sum().item()\n","        train_acc += (adv_outputs.argmax(1) == y).type(torch.float).sum().item()\n","\n","    train_loss /= num_batches\n","    train_acc /= (2*size)\n","    print(f\"HGD Train: \\n Accuracy: {(100*train_acc):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n","\n","    return train_loss, train_acc\n","\n","def validation_loop(dataloader, net, attack):\n","    loss_fn = nn.CrossEntropyLoss()\n","    net.eval()\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    total_loss,total_acc = 0, 0\n","    benign_loss, benign_acc = 0, 0\n","    adv_loss, adv_acc = 0, 0\n","    for batch,(X,y) in enumerate(dataloader):\n","      with torch.no_grad():\n","        X= X.to(device)\n","        y = y.to(device)\n","        _,denoised_clean,_ = net(X, X, requires_control = False, train = False)\n","        benign_loss += loss_fn(denoised_clean, y).item()\n","        benign_acc += (denoised_clean.argmax(1) == y).type(torch.float).sum().item()\n","      X.requires_grad = True\n","      adv = attack(X,y).to(device)\n","      X.requires_grad = False\n","      with torch.no_grad():\n","        _,denoised_adv,_ = net(X, adv, requires_control = False, train = False)\n","        adv_loss += loss_fn(denoised_adv, y).item()\n","        adv_acc += (denoised_adv.argmax(1) == y).type(torch.float).sum().item()\n","\n","    # Compute total loss and accuracy\n","    benign_loss /= num_batches\n","    benign_acc /= size\n","    adv_loss /= num_batches\n","    adv_acc /= size\n","    total_loss = (benign_loss + adv_loss) / 2\n","    total_acc = (benign_acc + adv_acc) / 2\n","    print('\\nTotal benign test accuarcy:', 100.*benign_acc)\n","    print('Total adversarial test Accuarcy:', 100.*adv_acc)\n","    print('Total benign test loss:', benign_loss)\n","    print('Total adversarial test loss:', adv_loss)\n","    print('**Summary**')\n","    print('Total validation accuracy:',100*total_acc)\n","    print('Total validiation loss:',total_loss)\n","\n","    return total_loss,total_acc,benign_loss,benign_acc,adv_loss,adv_acc"],"metadata":{"id":"sEmKNGm96vfS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run(net,optimizer,model_save_name,epochs):\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","   # Move model to device\n","    net = net.to(device)\n","    attack = PGD(net.net, eps=8/255,alpha=2/255,steps=7)\n","    best_validation_acc =  29.86\n","    for t in range(epochs):\n","        print(f\"Epoch {t+6}\\n-------------------------------\")\n","        train_loss, train_acc = train(trainloader, net, attack, optimizer)\n","        total_loss,total_acc,benign_loss,benign_acc,adv_loss,adv_acc = validation_loop(valloader, net, attack)\n","\n","        if total_acc > best_validation_acc:\n","            best_validation_acc = total_acc\n","            print(f\"Net at epoch {t+6} saved\")\n","            path = F\"/content/drive/MyDrive/AI_project/SaveModel/best_{model_save_name}\"\n","            torch.save(net.state_dict(), path)\n","        path = F\"/content/drive/MyDrive/AI_project/SaveModel/last_{model_save_name}\"\n","        torch.save(net.state_dict(), path)\n","\n","    print(\"Done!\")"],"metadata":{"id":"0WkzcRYTVn34"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 64\n","learning_rate=1e-3"],"metadata":{"id":"ND4OYom4Guw2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(42)\n","train_len = len(trainset)\n","num_train = int(train_len * 0.8)\n","num_val = train_len - num_train\n","train_set,val_set = random_split(trainset,[num_train, num_val])\n","\n","trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n","                                              shuffle=True, num_workers=2)\n","valloader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,\n","                                            shuffle=False, num_workers=2)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"YonvDSpO70pk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pre_res = ResNet50()\n","PATH = '/content/drive/MyDrive/AI_project/SaveModel/best_plain_res.pt'\n","pre_res.load_state_dict(torch.load(PATH))\n","\n","torch.manual_seed(42)\n","PATH = '/content/drive/MyDrive/AI_project/SaveModel/best_HGDnet_preplain.pt'\n","net = Net(pre_res,n=2)\n","net.load_state_dict(torch.load(PATH))\n","optimizer = optim.Adam(net.parameters(), lr=learning_rate,weight_decay=1e-4)\n","run(net,optimizer,model_save_name=\"HGDnet_preplain.pt\",epochs = 5)"],"metadata":{"id":"h7zQVui7BBpT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Testing on black box attack\n","def test_loop(dataloader, net, attack):\n","    loss_fn = nn.CrossEntropyLoss()\n","    net.eval()\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    total_loss,total_acc = 0, 0\n","    benign_loss, benign_acc = 0, 0\n","    adv_loss, adv_acc = 0, 0\n","    for batch,(X,y) in enumerate(dataloader):\n","      with torch.no_grad():\n","        X= X.to(device)\n","        y = y.to(device)\n","        _,denoised_clean,_ = net(X, X, requires_control = False, train = False)\n","        benign_loss += loss_fn(denoised_clean, y).item()\n","        benign_acc += (denoised_clean.argmax(1) == y).type(torch.float).sum().item()\n","      X.requires_grad = True\n","      adv = attack(X,y).to(device)\n","      X.requires_grad = False\n","      with torch.no_grad():\n","        _,denoised_adv,_ = net(X, adv, requires_control = False, train = False)\n","        adv_loss += loss_fn(denoised_adv, y).item()\n","        adv_acc += (denoised_adv.argmax(1) == y).type(torch.float).sum().item()\n","\n","    # Compute total loss and accuracy\n","    benign_loss /= num_batches\n","    benign_acc /= size\n","    adv_loss /= num_batches\n","    adv_acc /= size\n","    total_loss = (benign_loss + adv_loss) / 2\n","    total_acc = (benign_acc + adv_acc) / 2\n","    print('\\nTotal benign test accuarcy:', 100.*benign_acc)\n","    print('Total adversarial test Accuarcy:', 100.*adv_acc)\n","    print('Total benign test loss:', benign_loss)\n","    print('Total adversarial test loss:', adv_loss)\n","    print('**Summary**')\n","    print('Total Test accuracy:',100*total_acc)\n","    print('Total validation:',total_loss)\n","\n","    return total_loss,total_acc,benign_loss,benign_acc,adv_loss,adv_acc"],"metadata":{"id":"gcu3r5qEafb4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PATH = '/content/drive/MyDrive/AI_project/SaveModel/best_HGDnet_preplain.pt'\n","loaded_model = Net()\n","loaded_model.load_state_dict(torch.load(PATH))\n","loaded_model.to(device)\n","loaded_model.eval()\n","attack = PGD(loaded_model.net, eps=8/255,alpha=2/255,steps=7)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False,num_workers=2)\n","total_loss,total_acc,benign_loss,benign_acc,adv_loss,adv_acc = test_loop(testloader,loaded_model,attack)"],"metadata":{"id":"WGTPI1MHayJk"},"execution_count":null,"outputs":[]}]}